{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610e682c-d242-48de-a6fa-ca0ffce9fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7373e0bc-e6a7-4c64-8eb8-63969cb7304d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem',\n",
       " 'ipsum',\n",
       " 'dolor',\n",
       " 'sit',\n",
       " 'amet',\n",
       " ',',\n",
       " 'consectetur',\n",
       " 'adipiscing',\n",
       " 'elit',\n",
       " '.',\n",
       " 'Cras',\n",
       " 'dolor',\n",
       " 'nunc',\n",
       " ',',\n",
       " 'porta',\n",
       " 'et',\n",
       " 'sodales',\n",
       " 'et',\n",
       " ',',\n",
       " 'dignissim',\n",
       " 'a',\n",
       " 'enim',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras dolor nunc, porta et sodales et, dignissim a enim.\"\n",
    "\n",
    "# Transformer une phrase en liste de mots\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95483feb-f93d-47a8-a1f6-f4b86aa1acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem ipsum dolor sit amet, consectetur adipiscing elit.',\n",
       " 'Cras dolor nunc, porta et sodales et, dignissim a enim.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ou en liste de phrases\n",
    "sentences = nltk.tokenize.sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041f660a-1a8c-4a53-b733-520c1b70751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem',\n",
       " 'ipsum',\n",
       " 'dolor',\n",
       " 'sit',\n",
       " 'amet',\n",
       " 'consectetur',\n",
       " 'adipiscing',\n",
       " 'elit',\n",
       " 'Cras',\n",
       " 'dolor',\n",
       " 'nunc',\n",
       " 'porta',\n",
       " 'et',\n",
       " 'sodales',\n",
       " 'et',\n",
       " 'dignissim',\n",
       " 'a',\n",
       " 'enim']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supprimer la ponctuation avec un tokenizer personnalisé\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb261ab-5039-48a9-9c33-4c91ce148141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n",
      "fish\n",
      "fish\n",
      "fish\n"
     ]
    }
   ],
   "source": [
    "# Racinisation (stemming / lemmatizing) des mots\n",
    "words = [\"fisher\", \"fishing\", \"fish\", \"fishes\"]\n",
    "stemmer = nltk.stem.LancasterStemmer()\n",
    "for w in words:\n",
    "    print(stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78edf76a-0fce-4b35-906a-c338f64721c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lorem', 'ipsum'),\n",
       " ('ipsum', 'dolor'),\n",
       " ('dolor', 'sit'),\n",
       " ('sit', 'amet'),\n",
       " ('amet', ','),\n",
       " (',', 'consectetur'),\n",
       " ('consectetur', 'adipiscing'),\n",
       " ('adipiscing', 'elit'),\n",
       " ('elit', '.')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faire des bigrams pour le contexte\n",
    "text = sentences[0]\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "ngrams = list(nltk.bigrams(tokens))\n",
    "ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a97f5869-52a3-4c59-b69a-9c72d70c6913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'Lorem'),\n",
       " ('Lorem', 'ipsum'),\n",
       " ('ipsum', 'dolor'),\n",
       " ('dolor', 'sit'),\n",
       " ('sit', 'amet'),\n",
       " ('amet', ','),\n",
       " (',', 'consectetur'),\n",
       " ('consectetur', 'adipiscing'),\n",
       " ('adipiscing', 'elit'),\n",
       " ('elit', '.'),\n",
       " ('.', '</s>')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajouter les débuts et fins de phrase\n",
    "tokens = list(nltk.lm.preprocessing.pad_both_ends(tokens, n=2))\n",
    "ngrams = list(nltk.bigrams(tokens))\n",
    "ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "af183fb0-ca50-45a1-8439-bb6f5c1bdd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', consectetur dignissim'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les données doivent être une liste de phrase tokenizées\n",
    "corpus = [nltk.tokenize.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "# Fonction très pratique qui génère les n-grams (ici 2) et le vocabulaire\n",
    "train, vocab = nltk.lm.preprocessing.padded_everygram_pipeline(2, corpus)\n",
    "\n",
    "# Création et entraînement du modèle\n",
    "model = nltk.lm.MLE(2)\n",
    "model.fit(train, vocab)\n",
    "\n",
    "\n",
    "new_text = model.generate(1)\n",
    "new_text += \" \" + model.generate(1, new_text)\n",
    "new_text += \" \" + model.generate(1, new_text)\n",
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb88452-8aca-4903-a505-dfe61b570249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
